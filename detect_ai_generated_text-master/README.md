AI-Generated Text Detector

This project detects whether a piece of text is AI-generated or human-written by combining advanced NLP embeddings, linguistic analysis, and statistical scoring. It targets AI models like GPT-3 and beyond, leveraging semantic similarity, readability metrics, and perplexity-based evaluation.

ğŸš€ Key Features

BERT Embeddings â€” Generates semantic and contextual embeddings for the text.

Linguistic Analysis â€” Evaluates:

Flesch Reading Ease ğŸ“–

Fleschâ€“Kincaid Grade Level ğŸ“

Gunning Fog Index ğŸŒ«ï¸

Word frequency distributions ğŸ“Š

Pinecone Vector Database â€” Efficiently stores and retrieves embeddings.

Cosine Similarity â€” Measures similarity between input text and known AI-written samples.

Perplexity & Burstiness Scoring â€” Uses OpenAIâ€™s API for statistical text behavior analysis.

Interactive Streamlit App â€” User-friendly interface to test and visualize results.

ğŸ›  Methodology

Embedding Generation â€” Convert input text into high-dimensional BERT embeddings capturing deep semantic meaning.

Linguistic Feature Extraction â€” Compute readability scores, sentence complexity, and word distribution patterns.

Vector Similarity Search â€” Compare embeddings with a curated set of AI-generated and human-written text using cosine similarity.

Statistical Analysis â€” Calculate perplexity and burstiness to assess text predictability and variability.

Classification â€” Feed combined features into a classifier to label the text as AI-generated or human-written.

ğŸ“¦ Tech Stack

Language Model: BERT

Database: Pinecone Vector DB

Similarity Metric: Cosine Similarity

Readability Metrics: Flesch, Fleschâ€“Kincaid, Gunning Fog

API: OpenAI for perplexity & burstiness

UI: Streamlit